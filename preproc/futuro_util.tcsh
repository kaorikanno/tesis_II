#!/bin/tcsh -xef

echo "auto-generated by afni_proc.py, Tue Nov  7 15:19:45 2023"
echo "(version 7.17, July 16, 2021)"
echo "execution started: `date`"

# to execute via tcsh: 
#   tcsh -xef proc.100307 |& tee output.proc.100307
# to execute via bash: 
#   tcsh -xef proc.100307 2>&1 | tee output.proc.100307

# =============================== todos los sujetos procesar ==================================

# intento futuro de automatizar cosas

# sujetos actuales:

# 100307, 125424, 159845, 173536, 192035, 204319, 250932, 322224, 406836, 580650

set lista_sujetos = (100307 125424 159845 173536 192035 204319 250932 322224 406836 580650)

foreach subject ($lista_sujetos)

set subj = $subject
# assign output directory name
set output_dir = $subj.cortes.results

# verify that the results directory does not yet exist
if ( -d $output_dir ) then
    echo output dir "$subj.cortes.results" already exists
endif

# set list of runs
set runs = (`count -digits 2 1 1`)

# create results and stimuli directories
mkdir -p $output_dir
mkdir $output_dir/stimuli

# copy anatomy to results dir
3dcopy $subj/MNINonLinear_struc/T1w_restore.nii.gz \
     $output_dir/T1w_restore

# copy external motion file into results dir
cp /home/share/a/100307/rfMRI_REST1_LR/Movement_Regressors.txt $output_dir

# ============================ auto block: tcat ============================
# apply 3dTcat to copy input dsets to results dir,
# while removing the first 0 TRs
3dTcat -prefix $output_dir/pb00.$subj.r01.tcat \
   $subj/Results_MNINonLinear/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'[0..200]' \

# and make note of repetitions (TRs) per run
set tr_counts = ( 1200 )

# -------------------------------------------------------
# enter the results directory (can begin processing data)
cd $output_dir

# ========================== auto block: outcount ==========================
# data check: compute outlier fraction for each volume
touch out.pre_ss_warn.txt
foreach run ( $runs )
    3dToutcount -automask -fraction -polort 6 -legendre                     \
                pb00.$subj.r$run.tcat+tlrc > outcount.r$run.1D

    # censor outlier TRs per run, ignoring the first 0 TRs
    # - censor when more than 0.05 of automask voxels are outliers
    # - step() defines which TRs to remove via censoring
    1deval -a outcount.r$run.1D -expr "1-step(a-0.05)" > rm.out.cen.r$run.1D

    # outliers at TR 0 might suggest pre-steady state TRs
    if ( `1deval -a outcount.r$run.1D"{0}" -expr "step(a-0.4)"` ) then
        echo "** TR #0 outliers: possible pre-steady state TRs in run $run" \
            >> out.pre_ss_warn.txt
    endif
end

# catenate outlier counts into a single time series
cat outcount.r*.1D > outcount_rall.1D

# catenate outlier censor files into a single time series
cat rm.out.cen.r*.1D > outcount_${subj}_censor.1D


# ================================ despike =================================
# apply 3dDespike to each run
foreach run ( $runs )
    3dDespike -NEW -nomask -prefix pb01.$subj.r$run.despike \
        pb00.$subj.r$run.tcat+tlrc
end
# ================================== blur ==================================
# blur each volume of each run
foreach run ( $runs )
    3dmerge -1blur_fwhm 3.5 -doall -prefix pb02.$subj.r$run.blur \
            pb01.$subj.r$run.despike+tlrc
end
# ================================== mask ==================================
# create 'full_mask' dataset (union mask)
foreach run ( $runs )
    3dAutomask -prefix rm.mask_r$run pb02.$subj.r$run.blur+tlrc
end

# create union of inputs, output type is byte
3dmask_tool -inputs rm.mask_r*+tlrc.HEAD -union -prefix full_mask.$subj

# ---- segment anatomy into classes CSF/GM/WM ----
3dSeg -anat T1w_restore+tlrc -mask AUTO -classes 'CSF ; GM ; WM'

# copy resulting Classes dataset to current directory
3dcopy Segsy/Classes+tlrc .

# make individual ROI masks for regression (CSF GM WM and CSFe GMe WMe)
foreach class ( CSF GM WM )
   # unitize and resample individual class mask from composite
   3dmask_tool -input Segsy/Classes+tlrc"<$class>"                  \
               -prefix rm.mask_${class}
   3dresample -master pb02.$subj.r01.blur+tlrc -rmode NN            \
              -input rm.mask_${class}+tlrc -prefix mask_${class}_resam
   # also, generate eroded masks
   3dmask_tool -input Segsy/Classes+tlrc"<$class>" -dilate_input -1 \
               -prefix rm.mask_${class}e
   3dresample -master pb02.$subj.r01.blur+tlrc -rmode NN            \
              -input rm.mask_${class}e+tlrc -prefix mask_${class}e_resam
end
# ================================= scale ==================================
# scale each voxel time series to have a mean of 100
# (be sure no negatives creep in)
# (subject to a range of [0,200])
foreach run ( $runs )
    3dTstat -prefix rm.mean_r$run pb02.$subj.r$run.blur+tlrc
    3dcalc -a pb02.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \
           -expr 'min(200, a/b*100)*step(a)*step(b)'           \
           -prefix pb03.$subj.r$run.scale
end

# ================================ regress =================================

# compute de-meaned motion parameters (for use in regression)
1d_tool.py -infile Movement_Regressors.txt -set_nruns 1                  \
           -demean -write motion_demean.1D

# compute motion parameter derivatives (for use in regression)
1d_tool.py -infile Movement_Regressors.txt -set_nruns 1                  \
           -derivative -demean -write motion_deriv.1D

# convert motion parameters for per-run regression
1d_tool.py -infile motion_demean.1D -set_nruns 1                         \
           -split_into_pad_runs mot_demean

1d_tool.py -infile motion_deriv.1D -set_nruns 1                          \
           -split_into_pad_runs mot_deriv

# create censor file motion_${subj}_censor.1D, for censoring motion 
1d_tool.py -infile Movement_Regressors.txt -set_nruns 1                  \
    -show_censor_count -censor_prev_TR                                   \
    -censor_motion 0.2 motion_${subj}

# combine multiple censor files
1deval -a motion_${subj}_censor.1D -b outcount_${subj}_censor.1D         \
       -expr "a*b" > censor_${subj}_combined_2.1D

# note TRs that were not censored
set ktrs = `1d_tool.py -infile censor_${subj}_combined_2.1D              \
                       -show_trs_uncensored encoded`

# ------------------------------
# run the regression analysis
3dDeconvolve -input pb03.$subj.r*.scale+tlrc.HEAD                        \
    -censor censor_${subj}_combined_2.1D                                 \
    -ortvec mot_demean.r01.1D mot_demean_r01                             \
    -ortvec mot_deriv.r01.1D mot_deriv_r01                               \
    -polort 6 -float                                                     \
    -num_stimts 0                                                        \
    -fout -tout -x1D X.xmat.1D -xjpeg X.jpg                              \
    -x1D_uncensored X.nocensor.xmat.1D                                   \
    -fitts fitts.$subj                                                   \
    -errts errts.${subj}                                                 \
    -x1D_stop                                                            \
    -bucket stats.$subj

# -- use 3dTproject to project out regression matrix --
#    (make errts like 3dDeconvolve, but more quickly)
3dTproject -polort 0 -input pb03.$subj.r*.scale+tlrc.HEAD                \
           -censor censor_${subj}_combined_2.1D -cenmode ZERO            \
           -ort X.nocensor.xmat.1D -prefix errts.${subj}.tproject



# if 3dDeconvolve fails, terminate the script
if ( $status != 0 ) then
    echo '---------------------------------------'
    echo '** 3dDeconvolve error, failing...'
    echo '   (consider the file 3dDeconvolve.err)'
    exit
endif


# display any large pairwise correlations from the X-matrix
1d_tool.py -show_cormat_warnings -infile X.xmat.1D |& tee out.cormat_warn.txt

# display degrees of freedom info from X-matrix
1d_tool.py -show_df_info -infile X.xmat.1D |& tee out.df_info.txt

# create an all_runs dataset to match the fitts, errts, etc.
3dTcat -prefix all_runs.$subj pb03.$subj.r*.scale+tlrc.HEAD

# --------------------------------------------------
# create a temporal signal to noise ratio dataset 
#    signal: if 'scale' block, mean should be 100
#    noise : compute standard deviation of errts
3dTstat -mean -prefix rm.signal.all all_runs.$subj+tlrc"[$ktrs]"
3dTstat -stdev -prefix rm.noise.all errts.${subj}.tproject+tlrc"[$ktrs]"
3dcalc -a rm.signal.all+tlrc                                             \
       -b rm.noise.all+tlrc                                              \
       -expr 'a/b' -prefix TSNR.$subj

# ---------------------------------------------------
# compute and store GCOR (global correlation average)
# (sum of squares of global mean of unit errts)
3dTnorm -norm2 -prefix rm.errts.unit errts.${subj}.tproject+tlrc
3dmaskave -quiet -mask full_mask.$subj+tlrc rm.errts.unit+tlrc           \
          > mean.errts.unit.1D
3dTstat -sos -prefix - mean.errts.unit.1D\' > out.gcor.1D
echo "-- GCOR = `cat out.gcor.1D`"

# ---------------------------------------------------
# compute correlation volume
# (per voxel: correlation with masked brain average)
3dmaskave -quiet -mask full_mask.$subj+tlrc errts.${subj}.tproject+tlrc  \
          > mean.errts.1D
3dTcorr1D -prefix corr_brain errts.${subj}.tproject+tlrc mean.errts.1D

# --------------------------------------------------
# compute sum of baseline (all) regressors
3dTstat -sum -prefix sum_baseline.1D X.nocensor.xmat.1D

# ============================ blur estimation =============================
# compute blur estimates
touch blur_est.$subj.1D   # start with empty file

# create directory for ACF curve files
mkdir files_ACF

# -- estimate blur for each run in epits --
touch blur.epits.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask full_mask.$subj+tlrc                          \
            -ACF files_ACF/out.3dFWHMx.ACF.epits.r$run.1D                \
            all_runs.$subj+tlrc"[$trs]" >> blur.epits.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{0..$(2)}'\'` )
echo average epits FWHM blurs: $blurs
echo "$blurs   # epits FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.epits.1D'{1..$(2)}'\'` )
echo average epits ACF blurs: $blurs
echo "$blurs   # epits ACF blur estimates" >> blur_est.$subj.1D

# -- estimate blur for each run in errts --
touch blur.errts.1D

# restrict to uncensored TRs, per run
foreach run ( $runs )
    set trs = `1d_tool.py -infile X.xmat.1D -show_trs_uncensored encoded \
                          -show_trs_run $run`
    if ( $trs == "" ) continue
    3dFWHMx -detrend -mask full_mask.$subj+tlrc                          \
            -ACF files_ACF/out.3dFWHMx.ACF.errts.r$run.1D                \
            errts.${subj}.tproject+tlrc"[$trs]" >> blur.errts.1D
end

# compute average FWHM blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{0..$(2)}'\'` )
echo average errts FWHM blurs: $blurs
echo "$blurs   # errts FWHM blur estimates" >> blur_est.$subj.1D

# compute average ACF blur (from every other row) and append
set blurs = ( `3dTstat -mean -prefix - blur.errts.1D'{1..$(2)}'\'` )
echo average errts ACF blurs: $blurs
echo "$blurs   # errts ACF blur estimates" >> blur_est.$subj.1D


# ================== auto block: generate review scripts ===================

# generate a review script for the unprocessed EPI data
gen_epi_review.py -script @epi_review.$subj                             \
    -dsets pb00.$subj.r*.tcat+tlrc.HEAD

# generate scripts to review single subject results
# (try with defaults, but do not allow bad exit status)
gen_ss_review_scripts.py -exit0                                         \
    -mot_limit 0.2 -out_limit 0.05 -motion_dset Movement_Regressors.txt \
    -errts_dset errts.${subj}.tproject+tlrc.HEAD                        \
    -mask_dset full_mask.$subj+tlrc.HEAD                                \
    -ss_review_dset out.ss_review.$subj.txt                             \
    -write_uvars_json out.ss_review_uvars.json

# ========================== auto block: finalize ==========================

# remove temporary files
\rm -fr rm.* Segsy

# if the basic subject review script is here, run it
# (want this to be the last text output)
if ( -e @ss_review_basic ) then
    ./@ss_review_basic |& tee out.ss_review.$subj.txt

    # generate html ss review pages
    # (akin to static images from running @ss_review_driver)
    apqc_make_tcsh.py -review_style basic -subj_dir . \
        -uvar_json out.ss_review_uvars.json
    tcsh @ss_review_html |& tee out.review_html
    apqc_make_html.py -qc_dir QC_$subj

    echo "\nconsider running: \n\n    afni_open -b $subj.results/QC_$subj/index.html\n"
endif

# return to parent directory (just in case...)
cd ..

echo "execution finished: `date`"

